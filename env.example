# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=false

# Model Configuration
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
LLM_MODEL=mistralai/Mistral-7B-Instruct-v0.2
MAX_TOKENS=512
TEMPERATURE=0.7

# Vector Database
VECTOR_DIMENSION=384
FAISS_INDEX_PATH=models/faiss_index
TOP_K_RESULTS=5

# Data Sources
DATA_DIR=data
MODELS_DIR=models
CACHE_DIR=.cache

# Monitoring
ENABLE_MONITORING=true
METRICS_PORT=9090

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# GitHub Actions (for MLOps pipeline)
GITHUB_TOKEN=your_github_token_here
GITHUB_REPOSITORY=your_username/llm-powered-qa-system

# External APIs (optional)
OPENAI_API_KEY=your_openai_key_here
HUGGINGFACE_TOKEN=your_hf_token_here 